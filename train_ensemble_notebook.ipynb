{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "684d1ce1",
   "metadata": {},
   "source": [
    "# # Air-Senti-X Ensemble Training Notebook\n",
    "#\n",
    "# This notebook implements an end-to-end training pipeline for the Air-Senti-X project.\n",
    "# We:\n",
    "#\n",
    "# 1. Preprocess the dataset: Clean, split, encode, and tokenize the tweets.\n",
    "# 2. Build three BERT-based models with different architectures:\n",
    "#    - BERT+LSTM\n",
    "#    - BERT+BiLSTM\n",
    "#    - BERT+CNN\n",
    "# 3. Train each model with callbacks (TensorBoard logging, early stopping, and checkpoints).\n",
    "# 4. Ensemble the predictions using weighted averaging and apply confidence filtering.\n",
    "# 5. Evaluate the ensemble performance using accuracy, F1, and a confusion matrix.\n",
    "# 6. Save the trained models in H5 format and convert the best model to ONNX (optional).\n",
    "#\n",
    "# **Project Directory Structure:**\n",
    "# ```\n",
    "# Air-Senti-X/\n",
    "# ├── dataset/\n",
    "# │   └── Tweets.csv\n",
    "# ├── preprocessing/\n",
    "# │   ├── data_cleaning.py\n",
    "# │   ├── data_split_encode.py\n",
    "# │   └── tokenize_bert.py\n",
    "# ├── models/\n",
    "# │   ├── architectures/\n",
    "# │   │   ├── bert_lstm.py       # defines build_bert_lstm(max_len, num_labels)\n",
    "# │   │   ├── bert_bilstm.py     # defines build_bert_bilstm(max_len, num_labels)\n",
    "# │   │   └── bert_cnn.py        # defines build_bert_cnn(max_len, num_labels)\n",
    "# │   └── saved/                 # directory to store trained models\n",
    "# ├── utils/\n",
    "# │   ├── evaluation.py        # includes get_emotion() and calculate_urgency()\n",
    "# └── Train_Ensemble_All.ipynb   # This notebook\n",
    "# ```\n",
    "# \n",
    "# Make sure to install dependencies and that your virtual environment is activated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e134dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dhars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dhars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "c:\\Dharshan Raj P A\\Visual Studio Code\\Projects\\Air-Senti-X\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Dharshan Raj P A\\Visual Studio Code\\Projects\\Air-Senti-X\\venv\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Dharshan Raj P A\\Visual Studio Code\\Projects\\Air-Senti-X\\venv\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "import logging\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "\n",
    "# Import preprocessing functions\n",
    "from preprocessing.data_cleaning import preprocess_dataset\n",
    "from preprocessing.data_split_encode import split_and_encode\n",
    "from preprocessing.tokenize_bert import bert_tokenize\n",
    "\n",
    "# Import model builders\n",
    "from models.architectures.bert_lstm import build_bert_lstm\n",
    "from models.architectures.bert_bilstm import build_bert_bilstm\n",
    "from models.architectures.bert_cnn import build_bert_cnn\n",
    "\n",
    "from utils.evaluation import get_emotion, calculate_urgency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa6d441",
   "metadata": {},
   "source": [
    "# ## Configuration and Logging Setup\n",
    "#\n",
    "# We configure our training parameters and set up logging (both to console and a log file).\n",
    "#\n",
    "# We'll also set up TensorBoard logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7011583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_PATH = 'dataset/Tweets.csv'\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "ensemble_weights = [1.0, 1.0, 1.0]  # Equal weighting for each model\n",
    "CONFIDENCE_THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b691d7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for saving models and logs\n",
    "MODEL_SAVE_DIR = os.path.join(\"models\", \"saved\")\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "LOG_DIR = os.path.join(\"logs\", \"fit\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "os.makedirs(LOG_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1185d608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging to file\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)s: %(message)s',\n",
    "    filename='training.log',\n",
    "    filemode='w'\n",
    ")\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e921220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3471b040",
   "metadata": {},
   "source": [
    "# ## Step 1: Data Preprocessing\n",
    "#\n",
    "# We clean the dataset, split into training and testing sets, and tokenize the tweet text using the BERT tokenizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8856874b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Cleaning dataset...\n",
      "[INFO] Splitting dataset and encoding labels...\n",
      "[INFO] Tokenizing text using BERT...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Cleaning dataset...\")\n",
    "logger.info(\"Cleaning dataset...\")\n",
    "df = preprocess_dataset(DATA_PATH)\n",
    "\n",
    "print(\"[INFO] Splitting dataset and encoding labels...\")\n",
    "logger.info(\"Splitting dataset and encoding labels...\")\n",
    "train_df, test_df, train_labels, test_labels = split_and_encode(df, label_col='airline_sentiment')\n",
    "\n",
    "print(\"[INFO] Tokenizing text using BERT...\")\n",
    "logger.info(\"Tokenizing text using BERT...\")\n",
    "X_train_input_ids, X_train_attention_masks = bert_tokenize(train_df['text'].tolist(), max_len=MAX_LEN)\n",
    "X_test_input_ids, X_test_attention_masks = bert_tokenize(test_df['text'].tolist(), max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd26477",
   "metadata": {},
   "source": [
    "# ## Step 2: Model Building and Training\n",
    "#\n",
    "# We build three models with different architectures: BERT+LSTM, BERT+BiLSTM, and BERT+CNN.\n",
    "# Each model is compiled with an Adam optimizer and trained with early stopping and model checkpoint callbacks.\n",
    "#\n",
    "# We define a helper function `train_model` to train each model and return its predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6ed1485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Number of classes: 3\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(set(train_labels))\n",
    "print(f\"[INFO] Number of classes: {num_labels}\")\n",
    "logger.info(f\"Number of classes: {num_labels}\")\n",
    "\n",
    "def get_callbacks(model_name):\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(MODEL_SAVE_DIR, f\"{model_name}.h5\"),\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=2, restore_best_weights=True, verbose=1\n",
    "    )\n",
    "    return [checkpoint, early_stop, tensorboard_callback]\n",
    "\n",
    "def train_model(model_fn, model_name):\n",
    "    print(f\"[INFO] Building and training {model_name}...\")\n",
    "    logger.info(f\"Building and training {model_name}...\")\n",
    "    model = model_fn(MAX_LEN, num_labels)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    callbacks = get_callbacks(model_name)\n",
    "    model.fit(\n",
    "        [X_train_input_ids, X_train_attention_masks],\n",
    "        train_labels,\n",
    "        validation_split=0.1,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    # Save model is done in callbacks; return predictions on test set\n",
    "    preds = model.predict([X_test_input_ids, X_test_attention_masks])\n",
    "    return model, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74a4877f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Building and training bert_lstm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "325/325 [==============================] - ETA: 0s - loss: 0.5844 - accuracy: 0.7640 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.79481, saving model to models\\saved\\bert_lstm.h5\n",
      "325/325 [==============================] - 5573s 17s/step - loss: 0.5844 - accuracy: 0.7640 - val_loss: 0.4932 - val_accuracy: 0.7948\n",
      "91/91 [==============================] - 328s 4s/step\n",
      "[INFO] Building and training bert_bilstm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "325/325 [==============================] - ETA: 0s - loss: 0.5687 - accuracy: 0.7707 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.78961, saving model to models\\saved\\bert_bilstm.h5\n",
      "325/325 [==============================] - 3682s 11s/step - loss: 0.5687 - accuracy: 0.7707 - val_loss: 0.5004 - val_accuracy: 0.7896\n",
      "91/91 [==============================] - 334s 4s/step\n",
      "[INFO] Building and training bert_cnn...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "325/325 [==============================] - ETA: 0s - loss: 0.5948 - accuracy: 0.7584 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.78615, saving model to models\\saved\\bert_cnn.h5\n",
      "325/325 [==============================] - 6055s 19s/step - loss: 0.5948 - accuracy: 0.7584 - val_loss: 0.5052 - val_accuracy: 0.7861\n",
      "91/91 [==============================] - 385s 4s/step\n"
     ]
    }
   ],
   "source": [
    "# Train each model\n",
    "model_lstm, preds_lstm = train_model(build_bert_lstm, \"bert_lstm\")\n",
    "model_bilstm, preds_bilstm = train_model(build_bert_bilstm, \"bert_bilstm\")\n",
    "model_cnn, preds_cnn = train_model(build_bert_cnn, \"bert_cnn\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6926d518",
   "metadata": {},
   "source": [
    "# ## Step 3: Ensemble Predictions\n",
    "#\n",
    "# We combine the outputs of the three models by weighted averaging (soft voting).\n",
    "# We then determine the final predicted class, check the confidence of predictions,\n",
    "# and apply confidence-based filtering if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72bb979a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Ensemble predictions...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Ensemble predictions...\")\n",
    "logger.info(\"Ensembling predictions...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ef75bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to numpy arrays if needed\n",
    "all_preds = np.array([preds_lstm, preds_bilstm, preds_cnn])  # shape: (3, num_samples, num_labels)\n",
    "weighted_preds = np.average(all_preds, axis=0, weights=ensemble_weights)\n",
    "final_preds = tf.argmax(weighted_preds, axis=1).numpy()\n",
    "max_confidences = np.max(weighted_preds, axis=1)\n",
    "low_confidence_count = np.sum(max_confidences < CONFIDENCE_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59be62aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 185 predictions below confidence threshold.\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Low-confidence predictions: {low_confidence_count}\")\n",
    "print(f\"[INFO] {low_confidence_count} predictions below confidence threshold.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455c35a5",
   "metadata": {},
   "source": [
    "# ## Step 4: Evaluation\n",
    "#\n",
    "# We evaluate the ensemble performance using a classification report and a confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "628abd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT] Ensemble Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      1811\n",
      "           1       0.68      0.52      0.59       617\n",
      "           2       0.74      0.76      0.75       458\n",
      "\n",
      "    accuracy                           0.80      2886\n",
      "   macro avg       0.76      0.73      0.74      2886\n",
      "weighted avg       0.80      0.80      0.80      2886\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1655  102   54]\n",
      " [ 229  318   70]\n",
      " [  66   46  346]]\n"
     ]
    }
   ],
   "source": [
    "print(\"[RESULT] Ensemble Classification Report:\")\n",
    "report = classification_report(test_labels, final_preds)\n",
    "conf_matrix = confusion_matrix(test_labels, final_preds)\n",
    "print(report)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "logger.info(\"Classification Report:\\n\" + report)\n",
    "logger.info(\"Confusion Matrix:\\n\" + str(conf_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893a9505",
   "metadata": {},
   "source": [
    "# ## Step 5: Save Models and Convert Best Model to ONNX (Optional)\n",
    "#\n",
    "# We save each model in H5 format. We then attempt to convert the best model (based on average max confidence) to ONNX.\n",
    "# For ONNX conversion, ensure you have installed `tf2onnx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fe2a9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] bert_lstm model saved at models\\saved\\bert_lstm.h5\n",
      "[INFO] bert_bilstm model saved at models\\saved\\bert_bilstm.h5\n",
      "[INFO] bert_cnn model saved at models\\saved\\bert_cnn.h5\n"
     ]
    }
   ],
   "source": [
    "for model, name in zip([model_lstm, model_bilstm, model_cnn], [\"bert_lstm\", \"bert_bilstm\", \"bert_cnn\"]):\n",
    "    save_path = os.path.join(MODEL_SAVE_DIR, f\"{name}.h5\")\n",
    "    model.save(save_path)\n",
    "    logger.info(f\"{name} model saved at {save_path}\")\n",
    "    print(f\"[INFO] {name} model saved at {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db089aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Best model converted to ONNX and saved at models\\saved\\bert_bilstm.onnx\n",
      "[INFO] Training and ensemble evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "# Optional: Convert best model to ONNX\n",
    "try:\n",
    "    import tf2onnx\n",
    "    avg_confidences = [np.mean(np.max(pred, axis=1)) for pred in [preds_lstm, preds_bilstm, preds_cnn]]\n",
    "    best_idx = np.argmax(avg_confidences)\n",
    "    best_model = [model_lstm, model_bilstm, model_cnn][best_idx]\n",
    "    onnx_path = os.path.join(MODEL_SAVE_DIR, f\"{['bert_lstm','bert_bilstm','bert_cnn'][best_idx]}.onnx\")\n",
    "    spec = (tf.TensorSpec(best_model.inputs[0].shape, tf.int32, name=\"input_ids\"),\n",
    "            tf.TensorSpec(best_model.inputs[1].shape, tf.int32, name=\"attention_mask\"))\n",
    "    model_proto, _ = tf2onnx.convert.from_keras(best_model, input_signature=spec, opset=13)\n",
    "    with open(onnx_path, \"wb\") as f:\n",
    "        f.write(model_proto.SerializeToString())\n",
    "    logger.info(f\"Best model converted to ONNX and saved at {onnx_path}\")\n",
    "    print(f\"[INFO] Best model converted to ONNX and saved at {onnx_path}\")\n",
    "except ImportError:\n",
    "    logger.warning(\"tf2onnx not installed. Skipping ONNX conversion.\")\n",
    "    print(\"[WARNING] tf2onnx not installed. Skipping ONNX conversion.\")\n",
    "except Exception as e:\n",
    "    logger.error(\"Error during ONNX conversion: \" + str(e))\n",
    "    print(\"[ERROR] Error converting model to ONNX:\", e)\n",
    "\n",
    "logger.info(\"Training and ensemble evaluation complete.\")\n",
    "print(\"[INFO] Training and ensemble evaluation complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
